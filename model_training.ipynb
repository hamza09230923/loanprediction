{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Loan Prediction: Model Training and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load and Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\\n",
        "from sklearn.preprocessing import LabelEncoder\\n",
        "from sklearn.linear_model import LogisticRegression\\n",
        "from sklearn.ensemble import RandomForestClassifier\\n",
        "import xgboost as xgb\\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\\n",
        "\\n",
        "# Load the dataset\\n",
        "df = pd.read_csv('data/loan_train.csv')\\n",
        "\\n",
        "# Drop Loan_ID\\n",
        "df = df.drop('Loan_ID', axis=1)\\n",
        "\\n",
        "# Handle Missing Values\\n",
        "df['Gender'].fillna(df['Gender'].mode()[0], inplace=True)\\n",
        "df['Married'].fillna(df['Married'].mode()[0], inplace=True)\\n",
        "df['Dependents'].fillna(df['Dependents'].mode()[0], inplace=True)\\n",
        "df['Self_Employed'].fillna(df['Self_Employed'].mode()[0], inplace=True)\\n",
        "df['LoanAmount'].fillna(df['LoanAmount'].median(), inplace=True)\\n",
        "df['Loan_Amount_Term'].fillna(df['Loan_Amount_Term'].median(), inplace=True)\\n",
        "df['Credit_History'].fillna(df['Credit_History'].median(), inplace=True)\\n",
        "\\n",
        "# Categorical Feature Encoding\\n",
        "le = LabelEncoder()\\n",
        "for col in ['Gender', 'Married', 'Education', 'Self_Employed', 'Property_Area', 'Loan_Status', 'Dependents']:\\n",
        "    df[col] = le.fit_transform(df[col])\\n",
        "\\n",
        "# Split data into features (X) and target (y)\\n",
        "X = df.drop('Loan_Status', axis=1)\\n",
        "y = df['Loan_Status']\\n",
        "\\n",
        "# Split data into training and testing sets\\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Model Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models = {\\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000),\\n",
        "    'Random Forest': RandomForestClassifier(),\\n",
        "    'XGBoost': xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\\n",
        "}\\n",
        "\\n",
        "results = {\\n",
        "    'Model': [],\\n",
        "    'Accuracy': [],\\n",
        "    'Precision': [],\\n",
        "    'Recall': [],\\n",
        "    'F1-Score': [],\\n",
        "    'ROC-AUC': [],\\n",
        "    'CV_Accuracy': []\\n",
        "}\\n",
        "\\n",
        "for name, model in models.items():\\n",
        "    # Cross-validation\\n",
        "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\\n",
        "    results['CV_Accuracy'].append(cv_scores.mean())\\n",
        "    \\n",
        "    # Fit the model\\n",
        "    model.fit(X_train, y_train)\\n",
        "    \\n",
        "    # Make predictions\\n",
        "    y_pred = model.predict(X_test)\\n",
        "    y_pred_proba = model.predict_proba(X_test)[:, 1]\\n",
        "    \\n",
        "    # Evaluate metrics\\n",
        "    results['Model'].append(name)\\n",
        "    results['Accuracy'].append(accuracy_score(y_test, y_pred))\\n",
        "    results['Precision'].append(precision_score(y_test, y_pred))\\n",
        "    results['Recall'].append(recall_score(y_test, y_pred))\\n",
        "    results['F1-Score'].append(f1_score(y_test, y_pred))\\n",
        "    results['ROC-AUC'].append(roc_auc_score(y_test, y_pred_proba))\\n",
        "\\n",
        "results_df = pd.DataFrame(results)\\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Model Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_df"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}